
### Web development Projects

[Instagram-like App](https://github.com/amruta-11/IGconnector)

**Tools**:
* Backend - NodeJS, JavaScript, MongoDB and npm libraries like - Mongoose, Passport (for user authentication purpose), jsonwebtoken, bcrypyjs, nodemon.
* Frontend - React, HTML, CSS, JSX

**Project overview:**
 In this project I create a end to end web application. Firstly, I defined the MongoDB schemas and set up read and write to it through [Mongoose](https://mongoosejs.com/). After that, created the backend REST APIs using JavaScript. Developed the frontend using JavaScript, React, HTML & CSS and deployed it on Heroku.
 [Demo video link](https://drive.google.com/file/d/1F1ePuwZno8WfCbv70cj1GvwiqhHsRovI/view) 

### Data Science Projects

[Web Scraping & Analysis of Basketball Statistics](https://dataplatform.cloud.ibm.com/analytics/notebooks/v2/72f1ac0f-3ada-4503-8977-54ffdcb481f6/view?access_token=b310bf58d3677e9b995bfa42e49caa19cf7436833275167a15903951d854f3d5)
* Python library - Numpy, pandas, matplotlib
* For this project, I scrapped the statistics of the basketball players from Wikipedia pages to convert it into a Pandas data frame. Performed analysis of the data using Pandas, NumPy, and plotted the results using matplotlib and stored the results on the IBM cloud.


[NYC Flights Data - Part 1](https://amruta-11.github.io/projects/nycflight1.html)
* R library - tidyverse packages like dplyr, ggplot and nycflights13 from CRAN
**Project overview:**
In this project, initially I inspected the data by finding the dataframe size, knowing the variables and their data type, and finding out the number of missing values. I also summarized the data to know minimum and maximum observations in the variables. After thoroughly examining the dataset I formulated some questions to understand the statistics of the flight delays based on carrier and month of travel. To answer these questions I used the ggplot's bar chart and point graph.


[NYC Flights Data - Part 2](https://amruta-11.github.io/projects/nycflight2.html)
* R library - tidyverse packages like dplyr, ggplot and nycflights13 from CRAN
**Project overview:**
This is the continuation of NYC Flights Data Part 1 in which I focused on describing and summarizing the data using the dplyr verbs. I also used the dplyr verbs for answering the questions regarding flights delay.  


[Seattle Crime Data - Part 1](https://amruta-11.github.io/projects/seattlecrime1.html)
* R library - tidyverse packages like dplyr, stringr, tibble, censusr from CRAN and seattle crime data from seattle.gov
**Project overview:**
For this project, firstly I inspected the data to find the outliers and missing data and to know the variables within the data. Using the dplyr verbs like 'filter' and 'count', I was able to find the number of crimes occurred each year since 1973. I joined the crimedata, police beats data and the census data for the seattle region using a left joint. The outcome was a dataset with more than 500,000 observations and 47 variables.     


[Seattle Crime Data - Part 2](https://amruta-11.github.io/projects/seattlecrime2.html)
* R library - tidyverse packages like dplyr, ggplot and state data from R datasets.
**Project overview:**
This project has two parts - for the first part I loaded the states data, decribed all the variables in it and tidied the data. I performed analysis to examine the bivariate relationships between mumber rate and other variables. Second part of this project is a continuation of the Seattle Crime Data - Part 1 in which I performed data analysis to find out if there was any relationship between crime rates in Seattle and the educational attainment of the people.    
  

[Statistics - Probability & Normal Distribution](https://amruta-11.github.io/projects/stats&prob.html)
* R library - tidyverse packages like dplyr, stringr, tibble, height dataset and research citation dataset
**Project overview:**
In the first part of this project, I used the simple mathematical experssions & probability concepts to calulate the expected profits for the airlines if they overbook. For the second part, calculated the mean, median, mode and interquartile ranges for height & citation datasets. For each dataset, I also plotted the histogram and normal distribution curve to find out how they differ. 


[Statistics - Linear Regression](https://amruta-11.github.io/projects/linearreg.html)
* R library - tidyverse packages like dplyr, stringr, tibble
**Project overview:**
Firstly, I determined the response variable and predictor variable. For the housing data the 'medv' - median value of owner-occupied homes was the response variable and remaining 13 variables were the predicotrs. For each predictor I generated a linear model and plotted it using a geom smooth 'lm' method. I also fitted a multiple regression models for the response variable 'medv' and 13 predictors. Finally, I plotted univariate regression co-efficient on x-axis and multi-variate regression co-efficients on y-axis to find there relationship. 
